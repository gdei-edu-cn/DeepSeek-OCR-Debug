# è¿™æ˜¯ä¸ºäº†åœ¨æœ¬åœ°çš„ DeepSeek-OCR æ¨¡å‹ä¸Šæ‰¹é‡è·‘ Fox-100 æ•°æ®é›†çš„ä¸¤ç»„æ¨ç†é…ç½®ï¼švt64 å’Œ vt100ï¼Œå¹¶æŠŠæ¯å¼ å›¾çš„ OCR ç»“æœè¾“å‡ºä¸º JSONã€‚
# æ¨ç†è„šæœ¬
import sys
import os
import json
import torch

# ========== 0. è®¾ç½®å·¥ä½œç›®å½• ==========

script_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_dir)
print(f"âœ… å·¥ä½œç›®å½•å·²è®¾ç½®ä¸º: {os.getcwd()}")

# ========== 1. ç¦»çº¿æ¨¡å¼ï¼ˆå’Œä½ åŸæ¥ä¸€æ ·ï¼‰ ==========

os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_HUB_OFFLINE"] = "1"

# ========== 2. åŠ å…¥æœ¬åœ°åŒ…è·¯å¾„ï¼ˆè®© deepseek_ocr èƒ½ import åˆ°ï¼‰ ==========

sys.path.insert(0, "/newdata/home/liangweitang/Desktop/DeepSeek-OCR-debug/3rdparty")

from deepseek_ocr.modeling_deepseekocr import DeepseekOCRForCausalLM
from transformers import AutoConfig, AutoTokenizer

# ========== 3. è·¯å¾„é…ç½®ï¼šFox-100 ==========

# é¡¹ç›®æ ¹ç›®å½•ï¼šå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
PROJECT_ROOT = script_dir

# Fox æ•°æ®ç›®å½•ï¼šdata/Fox
FOX_DIR = os.path.join(PROJECT_ROOT, "data", "Fox")
EXP_DIR = os.path.join(FOX_DIR, "exp_fox100")
IMG_DIR = os.path.join(EXP_DIR, "images")  # ä½ å¯¼å‡ºçš„ 100 å¼  en_*.png åœ¨è¿™é‡Œ

# é¢„æµ‹ç»“æœè¾“å‡º
PRED_VT64_PATH = os.path.join(EXP_DIR, "preds_vt64.json")
PRED_VT100_PATH = os.path.join(EXP_DIR, "preds_vt100.json")

# ä¸´æ—¶ç»“æœç›®å½•ï¼ˆç»™ infer çš„ output_path å‚æ•°ç”¨ï¼‰
TMP_OUT_VT64 = os.path.join(EXP_DIR, "runs_vt64")
TMP_OUT_VT100 = os.path.join(EXP_DIR, "runs_vt100")

# OCR æç¤ºè¯ï¼šè®ºæ–‡åœ¨ Fox ä¸Šç”¨çš„æ˜¯æ— ç‰ˆé¢è¾“å‡º Free OCR
PROMPT_FREE_OCR = "<image>\nFree OCR."

# ========== 4. åŠ è½½æœ¬åœ° tokenizer / config / model ==========

def load_local_model():
    """
    ä½¿ç”¨ä½ æœ¬åœ°çš„ deepseek_ocr ç›®å½•åŠ è½½ tokenizerã€config å’Œ DeepseekOCRForCausalLM æ¨¡å‹
    """
    model_dir = "/newdata/home/liangweitang/Desktop/DeepSeek-OCR-debug/3rdparty/deepseek_ocr"

    print(f"ğŸ”„ æ­£åœ¨ä»æœ¬åœ°åŠ è½½ tokenizer å’Œ config: {model_dir}")
    tokenizer = AutoTokenizer.from_pretrained(
        model_dir,
        local_files_only=True
    )

    config = AutoConfig.from_pretrained(
        model_dir,
        local_files_only=True
    )

    print("ğŸ”„ æ­£åœ¨ä»æœ¬åœ°åŠ è½½ DeepseekOCRForCausalLM æƒé‡...")
    model = DeepseekOCRForCausalLM.from_pretrained(
        model_dir,
        config=config,
        torch_dtype=torch.bfloat16,
        local_files_only=True
    )

    if torch.cuda.is_available():
        model = model.eval().cuda()
        print("âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ° CUDA (bfloat16)")
    else:
        model = model.eval()
        print("âš  æœªæ£€æµ‹åˆ° GPUï¼Œå°†åœ¨ CPU ä¸Šè¿è¡Œï¼ˆä¼šå¾ˆæ…¢ï¼‰")

    return tokenizer, model

# ========== 5. éå† Fox-100 çš„å›¾ç‰‡åˆ—è¡¨ ==========

def list_fox100_images():
    assert os.path.isdir(IMG_DIR), f"âŒ æ‰¾ä¸åˆ° Fox-100 å›¾ç‰‡ç›®å½•: {IMG_DIR}"

    files = sorted(
        f for f in os.listdir(IMG_DIR)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    )
    print(f"ğŸ“‚ åœ¨ {IMG_DIR} æ‰¾åˆ°å›¾ç‰‡æ•°é‡: {len(files)}")
    if files:
        print("å‰ 5 å¼ å›¾ç‰‡:", files[:5])
    return files

# ========== 6. å¯¹ Fox-100 è·‘ä¸€éæŒ‡å®šé…ç½® ==========

def run_fox100_mode(tokenizer, model,
                    mode_name,
                    base_size,
                    image_size,
                    crop_mode,
                    tmp_out_dir,
                    json_out_path):
    """
    åœ¨ Fox-100 ä¸Šï¼Œç”¨æŒ‡å®šçš„ base_size / image_size / crop_mode è¿è¡Œä¸€éï¼Œ
    æŠŠæ¯å¼ å›¾ç‰‡çš„ OCR æ–‡æœ¬è¾“å‡ºåˆ° json_out_pathã€‚
    """
    os.makedirs(tmp_out_dir, exist_ok=True)

    images = list_fox100_images()
    # images = images[:1]   # â­ DEBUGï¼šåªä¿ç•™å‰ 1 å¼ å›¾ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜

    results = []

    print(f"\n=== å¼€å§‹è¿è¡Œæ¨¡å¼ {mode_name} ===")
    print(f"    base_size={base_size}, image_size={image_size}, crop_mode={crop_mode}")
    print(f"    ä¸´æ—¶è¾“å‡ºç›®å½•: {tmp_out_dir}")
    print(f"    è¾“å‡º JSON: {json_out_path}")

    for idx, img_name in enumerate(images):
        img_path = os.path.join(IMG_DIR, img_name)
        print(f"[{mode_name}] ({idx+1}/{len(images)}) å¤„ç† {img_name} ...")

        # è°ƒç”¨ä½ æœ¬åœ°çš„ DeepseekOCRForCausalLM.infer æ¥å£
        # å‚æ•°å«ä¹‰ï¼š
        # - prompt: ä½¿ç”¨ Free OCR æç¤ºï¼Œä¸å¸¦ç‰ˆé¢
        # - image_file: Fox é¡µé¢çš„å›¾ç‰‡è·¯å¾„
        # - output_path: æ¨¡å‹å†…éƒ¨ä¿å­˜å›¾åƒ/ä¸­é—´ç»“æœçš„ç›®å½•
        # - base_size / image_size / crop_mode: æ§åˆ¶è§†è§‰ token æ•°å’Œåˆ†è¾¨ç‡
        # - save_results=False: ä¸å¿…ä¿å­˜æ¯å¼ å›¾çš„å¯è§†åŒ–ç»“æœï¼ŒèŠ‚çœç©ºé—´
        # - test_compress=True: åœ¨ç»ˆç«¯æ‰“å°å‹ç¼©æ¯”ç­‰ä¿¡æ¯ï¼Œæ–¹ä¾¿ä¹‹åå†™è®ºæ–‡
        res = model.infer(
            tokenizer,
            prompt=PROMPT_FREE_OCR,
            image_file=img_path,
            output_path=tmp_out_dir,
            base_size=base_size,
            image_size=image_size,
            crop_mode=crop_mode,
            save_results=False,
            test_compress=True,   # è¦æ‰“å°å‹ç¼©ä¿¡æ¯å¯ä»¥ä¿ç•™ True
            eval_mode=True        # â­ å…³é”®ï¼šè®© infer è¿”å› OCR æ–‡æœ¬
        )

        # infer åœ¨ eval_mode=True æ—¶åº”è¯¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
        if res is None:
            print(f"âš ï¸ infer è¿”å› None: {img_name}ï¼Œå…ˆå†™ç©ºå­—ç¬¦ä¸²ï¼Œåé¢å†æ’æŸ¥")
            pred_text = ""
        elif isinstance(res, str):
            pred_text = res
        else:
            # ä¿é™©èµ·è§ï¼Œå¦‚æœæ˜¯åˆ«çš„ç»“æ„ï¼Œå…ˆè½¬æˆå­—ç¬¦ä¸²
            pred_text = str(res)

        results.append({
            "image": img_name,
            "pred": pred_text
        })


    # å†™å‡º JSON æ–‡ä»¶
    with open(json_out_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ¨¡å¼ {mode_name} å®Œæˆï¼Œå…±å¤„ç† {len(results)} é¡µã€‚")
    print(f"   é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {json_out_path}")

# ========== 7. ä¸»å‡½æ•°ï¼šè·‘ vt64 + vt100 ==========

def main():
    print("ğŸ“Œ PROJECT_ROOT:", PROJECT_ROOT)
    print("ğŸ“Œ FOX_DIR:", FOX_DIR)
    print("ğŸ“Œ FOX exp_fox100 ç›®å½•:", EXP_DIR)
    print("ğŸ“Œ å›¾ç‰‡ç›®å½• IMG_DIR:", IMG_DIR)

    tokenizer, model = load_local_model()

    # --- æ¨¡å¼ 1ï¼švt=64ï¼ŒTiny é£æ ¼ ---
    # æ¨èï¼šbase_size=512, image_size=512, crop_mode=False
    run_fox100_mode(
        tokenizer=tokenizer,
        model=model,
        mode_name="vt64",
        base_size=512,
        image_size=512,
        crop_mode=False,
        tmp_out_dir=TMP_OUT_VT64,
        json_out_path=PRED_VT64_PATH
    )

    # --- æ¨¡å¼ 2ï¼švt=100ï¼ŒSmall é£æ ¼ ---
    # æ¨èï¼šbase_size=640, image_size=640, crop_mode=False
    run_fox100_mode(
        tokenizer=tokenizer,
        model=model,
        mode_name="vt100",
        base_size=640,
        image_size=640,
        crop_mode=False,
        tmp_out_dir=TMP_OUT_VT100,
        json_out_path=PRED_VT100_PATH
    )

    print("\nğŸ‰ æ‰€æœ‰ Fox-100 æ¨ç†å®Œæˆï¼")
    print(f"   vt=64 ç»“æœ: {PRED_VT64_PATH}")
    print(f"   vt=100 ç»“æœ: {PRED_VT100_PATH}")

if __name__ == "__main__":
    main()
